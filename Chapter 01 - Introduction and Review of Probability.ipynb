{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.1**.  Let $A_1$ and $A_2$ be arbitrary events and show that $\\text{Pr}\\{A_1 \\cup A_2\\} + \\text{Pr}\\{A_1 A_2\\} = \\text{Pr}\\{A_1\\} + \\text{Pr}\\{A_2\\}$.  Explain which parts of the sample space are being double counted on both sides of this equation and which parts are being counted once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.  Consider the disjoint events $A_1 - A_2, A_2 - A_1, A_1 A_2$, where $X - Y = \\{ \\omega : \\omega \\in X \\text{ and not } \\omega \\in Y \\}$.  \n",
    "\n",
    "By construction these events are disjoint: any event $\\omega$ either:\n",
    "\n",
    "- belongs to $A_1$ but not $A_2$, in which case $\\omega \\in A_1 - A_2$ but it does not belong to $A_2 - A_1$ or $A_1 A_2$;\n",
    "- belongs to $A_2$ but not $A_1$, in which case $\\omega \\in A_2 - A_1$ but it does not belong to $A_1 - A_2$ or $A_1 A_2$;\n",
    "- belongs to both $A_1$ and $A_2$, in which case $\\omega \\in A_1 A_2$ but it does not belong to $A_1 - A_2$ or $A_2 - A_1$;\n",
    "- does not belong to $A_1$ or $A_2$, in which case it does not belong to any of $A_1 - A_2, A_2 - A_1, A_1 A_2$.\n",
    "\n",
    "Also note that:\n",
    "\n",
    "- $(A_1 - A_2) \\cup A_1 A_2 = A_1$, since any event that belongs to $A_1$ either belongs to $A_2$ (in which case it belongs to $A_1 A_2$) or not (in which case it belongs to $A_1 - A_2$).\n",
    "- $(A_2 - A_1) \\cup A_1 A_2 = A_2$, by a similar argument.\n",
    "- $(A_1 - A_2) \\cup (A_2 - A_1) \\cup A_1 A_2 = A_1 \\cup A_2$, by applying the union over the previous two statements.\n",
    "\n",
    "By the third axiom of probability (using the finite version -- add infinitely many empty to get an infinite sequence) we get:\n",
    "\n",
    "1.  $\\text{Pr}\\{A_1 - A_2\\} + \\text{Pr}\\{ A_1 A_2 \\} = \\text{Pr}\\{A_1\\} $\n",
    "2.  $\\text{Pr}\\{A_2 - A_1\\} + \\text{Pr}\\{ A_1 A_2 \\} = \\text{Pr}\\{A_2\\} $\n",
    "3.  $\\text{Pr}\\{A_1 \\cup A_2 \\} = \\text{Pr}\\{A_1 - A_2\\} + \\text{Pr}\\{ A_2 - A_1 \\} + \\text{Pr}\\{ A_1 A_2 \\}$\n",
    "\n",
    "Adding these three statements, we get the desired result,\n",
    "\n",
    "$$\\text{Pr}\\{A_1 \\cup A_2\\} + \\text{Pr}\\{A_1 A_2\\} = \\text{Pr}\\{A_1\\} + \\text{Pr}\\{A_2\\}$$\n",
    "\n",
    "Note that:\n",
    "\n",
    "- If $\\omega \\in A_1$ and $\\omega \\in A_2$, it is counted twice in each side of the equation -- once in $\\text{Pr}\\{A_1 \\cup A_2\\}$, once in $\\text{Pr}\\{A_1 A_2\\}$, once in $\\text{Pr}\\{A_1\\}$ and once in $\\text{Pr}\\{A_2\\}$.\n",
    "- If $\\omega \\in A_1$ but $\\text{not } \\omega \\in A_2$, it is counted once in each side of the equation -- once in $\\text{Pr}\\{A_1 \\cup A_2\\}$ and once in $\\text{Pr}\\{A_1\\}$.\n",
    "- If $\\omega \\in A_2$ but $\\text{not } \\omega \\in A_1$, it is counted once in each side of the equation -- once in $\\text{Pr}\\{A_1 \\cup A_2\\}$ and once in $\\text{Pr}\\{A_2\\}$.\n",
    "- If $\\text{not } \\omega \\in A_1$ and $\\text{not } \\omega \\in A_2$, it is counted zero times in each side of the equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.2**.  This exercise derives the probability of an arbitrary (non-disjoint) union of events, derives the union bound, and derives some useful limit expressions.\n",
    "\n",
    "**(a)** For two arbitrary events $A_1$ and $A_2$, show that\n",
    "\n",
    "$$ A_1 \\cup A_2 = A_1 \\cup (A_2 - A_1) \\quad \\text{where } A_2 - A_1 = A_2 A_1^c$$\n",
    "\n",
    "Show that $A_1$ and $A_2 - A_1$ are disjoint.  Hint:  Venn diagrams were invented to help understand expressions like these.\n",
    "\n",
    "**(b)** For an arbitrary sequence of events, $\\{A_n : n \\geq 1\\}$, let $B_1 = A_1$ and for each $n \\geq 2$ define $B_n = A_n - \\cup_{m=1}^{n - 1} A_m$.  Show that $B_1, B_2, \\dots$ are disjoint events and show that for each $n \\geq 2$, $\\cup_{m=1}^n A_m = \\cup_{m=1}^n B_m$.  Hint: Use induction.\n",
    "\n",
    "**(c)** Show that\n",
    "\n",
    "$$ \\text{Pr}\\left\\{ \\cup_{n=1}^\\infty A_n \\right\\} = \\text{Pr}\\left\\{ \\cup_{n=1}^\\infty B_n \\right\\} = \\sum_{n=1}^\\infty \\text{Pr} \\left\\{ B_n \\right\\} $$\n",
    "\n",
    "Hint: Use the axioms of probability for the second equality.\n",
    "\n",
    "**(d)** Show that for each $n$, $\\text{Pr}\\left\\{ B_n \\right\\} \\leq \\text{Pr} \\left\\{ A_n \\right\\}$.  Use this to show that\n",
    "\n",
    "$$ \\text{Pr}\\left\\{ \\cup_{n=1}^\\infty A_n \\right\\} \\leq \\sum_{n=1}^\\infty \\text{Pr} \\left\\{ A_n \\right\\} $$\n",
    "\n",
    "**(e)** Show that $\\text{Pr}\\left\\{ \\cup_{n=1}^\\infty A_n \\right\\} = \\lim_{m \\rightarrow \\infty} \\text{Pr} \\left\\{ \\cup_{n=1}^m A_n \\right\\}$.  Hint: Combine (c) and (b).  Note that this says that the probability of a limit of unions is equal to the limit of probabilities.  This might well appear to be obvious without a proof, but you will see situations later where similar appearing interchanges cannot be made.\n",
    "\n",
    "**(f)** Show that $\\text{Pr}\\left\\{ \\cap_{n=1}^\\infty A_n \\right\\} = \\lim_{n \\rightarrow \\infty} \\text{Pr}\\left\\{ \\cap_{i=1}^n A_i \\right\\}$.  Hint: Remember De Morgan's equalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  We have:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "&\\omega \\in A_1 \\cup A_2 \\\\\n",
    "&\\Longleftrightarrow (\\omega \\in A_1) \\lor (\\omega \\in A_2) \\\\\n",
    "&\\Longleftrightarrow (\\omega \\in A_1) \\lor (\\omega \\in A_2 \\land \\neg(\\omega \\in A_1)) \\\\\n",
    "&\\Longleftrightarrow (\\omega \\in A_1) \\lor (\\omega \\in (A_2 - A_1)) \\\\\n",
    "&\\Longleftrightarrow \\omega \\in A_1 \\cup (A_2 - A_1) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where we can explicitly verify the third step with a truth table:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc|c|c}\n",
    "\\omega \\in A_1 & \\omega \\in A_2 & (\\omega \\in A_1) \\lor (\\omega \\in A_2) & (\\omega \\in A_1) \\lor (\\omega \\in A_2 \\land \\neg(\\omega \\in A_1)) \\\\\n",
    "\\hline\n",
    "T & T & T & T \\\\\n",
    "T & F & T & T \\\\\n",
    "F & T & T & T \\\\\n",
    "F & F & F & F\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Since the sets $A_1 \\cup A_2$ and $A_1 \\cup (A_2 - A_1)$ have equivalent statements determining whether a granular event $\\omega$ belongs to them, they are equal,\n",
    "\n",
    "$$ A_1 \\cup A_2 = A_1 \\cup (A_2 - A_1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  Let's use induction.\n",
    "\n",
    "For the base case, $n = 2$, we have $B_2 = A_2 - A_1$.  \n",
    "- Note that $B_1 = A_1$ and $B_2$ are disjoint events by construction: every element from $A_1$ is explicitly excluded from $B_2$.  \n",
    "- Also note that $A_1 \\cup A_2 = B_1 \\cup B_2$, since $B_1 \\cup B_2 = A_1 \\cup (A_2 - A_1)$, and this is the result proved in (a).\n",
    "\n",
    "For the induction step, assume the result is true for $n$.  \n",
    "- Since $B_{n + 1} = A_n - \\cup_{i=1}^n A_m$, any element belonging to $B_{n+1}$ will not belong to any of the $A_m$ for $1 \\leq m \\leq n$ by construction, and since from the previous step $\\cup_{m=1}^n A_m = \\cup_{m=1}^n B_m$, it will also not belong to any $B_m$, $1 \\leq m \\leq n$.  Therefore there is no overlap between $B_{n + 1}$ and $B_m$, and the $B_i$'s are disjoint.\n",
    "- Finally, note that, from applying (a) on sets $A_{n + 1}$ and $\\cup_{m=1}^n A_m$,\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "A_{n + 1} \\cup \\left( \\cup_{m=1}^n A_m \\right) &= \\left( \\cup_{m=1}^n A_m \\right) \\cup \\left(A_{n+1} - \\left( \\cup_{m=1}^n A_m \\right)  \\right) \\\\ \n",
    "A_{n + 1} \\cup \\left( \\cup_{m=1}^n A_m \\right) &= \\left( \\cup_{m=1}^n B_m \\right) \\cup B_{n+1} \\\\\n",
    "\\cup_{m=1}^{n+1} A_m &= \\cup_{m=1}^{n+1} B_m \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**  The result follows from the third axiom of inequality, since all of the $B_i$'s are disjoint by (b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**  We have $B_n = A_n - \\cup_{m=1}^{n - 1} A_m = A_n - \\cup_{m=1}^{n - 1} B_m$, and so uniting both sides to $\\cup_{m=1}^{n - 1} B_m$ we get $\\cup_{m=1}^{n} B_m = A_n$.  Since the $B_i$'s are disjoint, by the third axiom of probability we have\n",
    "\n",
    "$$ \\text{Pr}\\left\\{A_n\\right\\} = \\sum_{m=1}^n \\text{Pr}\\left\\{ B_m \\right\\} = \\sum_{m=1}^{n - 1} \\text{Pr}\\left\\{ B_m \\right\\} + \\text{Pr}\\left\\{B_n\\right\\}$$\n",
    "\n",
    "and, since for the first axiom of probability,  $\\text{Pr} \\left\\{ B_m \\right\\} \\geq 0$ for $1 \\leq m \\leq n - 1$, we get\n",
    "\n",
    "$$ \\text{Pr}\\left\\{A_n\\right\\} \\geq \\text{Pr}\\left\\{B_n\\right\\} $$\n",
    "\n",
    "Finally, using this inequality for each $n$, and from (b), we have\n",
    "\n",
    "$$ \\text{Pr}\\left\\{ \\cup_{n=1}^\\infty A_n \\right\\} \n",
    "= \\text{Pr}\\left\\{ \\cup_{n=1}^\\infty B_n \\right\\} \n",
    "= \\sum_{n=1}^\\infty \\text{Pr} \\left \\{ B_n \\right\\}\n",
    "\\leq \\sum_{n=1}^\\infty \\text{Pr} \\left\\{ A_n \\right\\} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)**  The result from (c) states that\n",
    "\n",
    "$$ \\text{Pr}\\left\\{ \\cup_{n=1}^\\infty A_n \\right\\} = \\text{Pr}\\left\\{ \\cup_{n=1}^\\infty B_n \\right\\} = \\sum_{n=1}^\\infty \\text{Pr} \\left\\{ B_n \\right\\} $$\n",
    "\n",
    "In particular, we can consider a different sequence of sets, $A'_1, A'_2, \\dots$ and $B'_1, B'_2, \\dots$, where\n",
    "\n",
    "$$\n",
    "A'_k = \\begin{cases}\n",
    "A_k &\\text{if } k \\leq n \\\\\n",
    "A_n &\\text{if } k > n\n",
    "\\end{cases}\n",
    "\\quad \\text{and} \\quad\n",
    "B'_k = \\begin{cases}\n",
    "B_k &\\text{if } k \\leq n \\\\\n",
    "\\varnothing &\\text{if } k >n\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Since the previous results also apply to these sequences of sets, the finite version of the result is also valid for every $n$,\n",
    "\n",
    "$$ \\text{Pr}\\left\\{ \\cup_{m=1}^n A_m \\right\\} = \\text{Pr}\\left\\{ \\cup_{m=1}^n B_m \\right\\} = \\sum_{m=1}^n \\text{Pr} \\left\\{ B_m \\right\\} $$\n",
    "\n",
    "But\n",
    "\n",
    "$$ \\lim_{n \\rightarrow \\infty} \\sum_{m=1}^n \\text{Pr} \\left\\{ B_m \\right\\} = \\sum_{n=1}^\\infty \\text{Pr} \\left\\{ B_n \\right\\} $$\n",
    "\n",
    "which exists and is bound between 0 and 1 inclusive, since the right hand value the probability $\\text{Pr}\\left\\{ \\cup_{n=1}^\\infty A_n \\right\\}$.\n",
    "\n",
    "Therefore, by taking the limit to the result on finite sequences, we get\n",
    "\n",
    "$$  \\lim_{n \\rightarrow \\infty} \\text{Pr}\\left\\{ \\cup_{m=1}^n A_m \\right\\} = \\sum_{n=1}^\\infty \\text{Pr} \\left\\{ B_n \\right\\} = \\text{Pr}\\left\\{ \\cup_{n=1}^\\infty A_n \\right\\} $$\n",
    "\n",
    "which is the desired result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)**  De Morgan's equality states that\n",
    "\n",
    "$$ \\left(\\cap_{n=1}^\\infty A_n \\right)^c = \\cup_{n=1}^\\infty A_n^c $$\n",
    "\n",
    "By applying the result of (e) to the sequence of complements $A_1^c, A_2^c, \\dots$ we get:\n",
    "\n",
    "$$ \\lim_{n \\rightarrow \\infty} \\text{Pr}\\left\\{ \\cup_{m=1}^n A_m^c \\right\\} = \\text{Pr}\\left\\{ \\cup_{n=1}^\\infty A_n^c \\right\\} $$\n",
    "\n",
    "and using the fact that $\\text{Pr}\\left\\{ X \\right\\} + \\text{Pr}\\left\\{ X^c \\right\\} = 1$ we get\n",
    "\n",
    "$$ \\lim_{n \\rightarrow \\infty} 1 - \\text{Pr}\\left\\{ \\cap_{m=1}^n A_m \\right\\} = 1 - \\text{Pr}\\left\\{ \\cap_{n=1}^\\infty A_n \\right\\} $$\n",
    "\n",
    "from which the result follows,\n",
    "\n",
    "$$ \\lim_{n \\rightarrow \\infty} \\text{Pr}\\left\\{ \\cap_{m=1}^n A_m \\right\\} = \\text{Pr}\\left\\{ \\cap_{n=1}^\\infty A_n \\right\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.3**.  Find the probability that a five-card poker hand, chosen randomly from a 52-card deck, contains four aces.  That is, if all $52!$ arrangements of a deck of cards are equally likely, what is the probability that all four aces are in the first five cards of the deck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**. There are $52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot 48$ ordered sequences for the first five cards of the deck.  Of those, the sequences containing four aces correspond to choosing the four aces in some order ($4 \\cdot 3 \\cdot 2 \\cdot 1$), then selecting a fifth card ($48$ choices) and inserting it somewhere alongside the first four cards ($5$ position choices).\n",
    "\n",
    "Therefore, the desired probability is\n",
    "\n",
    "$$ \\frac{(4 \\cdot 3 \\cdot 2 \\cdot 1) \\cdot 48 \\cdot 5}{52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot 48} = \\frac{1}{54145} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.4**. Consider a sample space of eight equiprobable sample points and let $A_1, A_2, A_3$ be three events each of probability $1/2$ such that $\\text{Pr}\\{ A_1 A_2 A_3 \\} = \\text{Pr}\\{A_1\\}\\text{Pr}\\{A_2\\}\\text{Pr}\\{A_3\\}$.\n",
    "\n",
    "**(a)** Create an example where $\\text{Pr}\\{ A_1 A_2 \\} = \\text{Pr}\\{ A_1 A_3 \\} = 1/4$ but $\\text{Pr}\\{ A_2 A_3 \\} = 1/8$.  Hint:  make a table with a row for each sample point and a column for each event and try different ways of assigning sample points to events (the answer is not unique).\n",
    "\n",
    "**(b)** Show that, for your example, $A_2$ and $A_3$ are not independent.  Note that the definition of statistical independence would be very strange indeed if it allowed $A_1, A_2, A_3$ to be independent while $A_2$ and $A_3$ are dependent.  This illustrates why the definition of independence requires (1.14) rather than just (1.15)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**\n",
    "\n",
    "Let the sample space be $\\Omega = \\{ \\omega_i : 1 \\leq i \\leq 8, i \\in \\mathbb{N} \\}$, with a probability distribution $\\text{Pr}\\{ \\omega_i \\} = 1/8$ for each $i$.  Consider the events $A_1, A_2, A_3$ specified by:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccc|c|c|c|c}\n",
    "\\omega & A_1 & A_2 & A_3 & A_1 A_2 A_3 & A_1 A_2 & A_1 A_3 & A_2 A_3 \\\\\n",
    "\\hline\n",
    "\\omega_1 & T & T & T & T & T & T & T \\\\ \n",
    "\\omega_2 & T & T & F & F & T & F & F \\\\\n",
    "\\omega_3 & T & F & T & F & F & T & F \\\\\n",
    "\\omega_4 & T & F & F & F & F & F & F \\\\\n",
    "\\omega_5 & F & T & F & F & F & F & F \\\\\n",
    "\\omega_6 & F & T & F & F & F & F & F \\\\\n",
    "\\omega_7 & F & F & T & F & F & F & F \\\\\n",
    "\\omega_8 & F & F & T & F & F & F & F \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Or, with set notation:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "A_1 &= \\{ \\omega_1, \\omega_2, \\omega_3, \\omega_4 \\} \\\\\n",
    "A_2 &= \\{ \\omega_1, \\omega_2, \\omega_5, \\omega_6 \\} \\\\\n",
    "A_3 &= \\{ \\omega_1, \\omega_3, \\omega_7, \\omega_8 \\}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which leads to:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "A_1 A_2 A_3 &= \\{ \\omega_1 \\} \\\\\n",
    "A_1 A_2 &= \\{ \\omega_1, \\omega_2 \\} \\\\\n",
    "A_1 A_3 &= \\{ \\omega_1, \\omega_3 \\} \\\\\n",
    "A_2 A_3 &= \\{ \\omega_1 \\}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since $\\{ \\omega_i \\}$ are disjoint for each $i$ and $\\text{Pr}\\{ \\omega_i \\} = 1/8$ for each $i$, the desired properties follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  In this example, $A_2$ and $A_3$ are not independent, as $\\text{Pr}\\{A_2\\} = \\text{Pr}\\{ A_3 \\} = 1/2$ and $\\text{Pr}\\{A_2 A_3\\} = 1/8$, so $\\text{Pr}\\{A_2 A_3\\} \\neq \\text{Pr}\\{A_2\\} \\text{Pr}\\{A_3\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.5**.  This exercise shows that for all random variables $X$, $F_X(x)$ is continuous from the right.\n",
    "\n",
    "**(a)** For any given random variable $X$, any real number $x$, and each integer $n \\geq 1$, let $A_n = \\{ \\omega : X > x + 1/  n \\}$, and show that $A_1 \\subseteq A_2 \\subseteq \\cdots$.  Use this and the corollaries to the axioms of probability to show that $\\text{Pr} \\left\\{ \\cup_{n \\geq 1} A_n \\right\\} = \\lim_{n \\rightarrow \\infty} \\text{Pr}\\left\\{A_n\\right\\}$.\n",
    "\n",
    "**(b)** Show that $\\text{Pr}\\left\\{ \\cup_{n \\geq 1} A_n \\right\\} = \\text{Pr}\\left\\{ X > x \\right\\}$ and that $\\text{Pr}\\left\\{ X > x \\right\\} = \\lim_{n \\rightarrow \\infty}\\text{Pr}\\left\\{ X > x + 1 / n \\right\\}$.\n",
    "\n",
    "**(c)** Show that for $\\epsilon > 0$, $\\lim_{\\epsilon \\rightarrow 0} \\text{Pr} \\left\\{ X \\leq x + \\epsilon \\right\\} = \\text{Pr}\\left\\{ X \\leq x \\right\\}$.\n",
    "\n",
    "**(d)** Define $\\tilde{F}_X(x) = \\text{Pr}\\left\\{ X < x \\right\\}$.  Show that $\\tilde{F}_X(x)$ is continuous from the left.  In other words, the continuity from the right for the CDF arises from the almost arbitrary (but universally accepted) choice in defining the CDF as $\\text{Pr}\\left\\{ X \\leq x \\right\\}$ rather than $\\text{Pr}\\left\\{ X < x \\right\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  We have, for every $n \\geq 1$,\n",
    "\n",
    "$$ \\omega \\in A_n \\Rightarrow X(\\omega) > x + 1/n \\Rightarrow X(\\omega) > x + 1 / (n + 1) \\Rightarrow \\omega \\in A_{n+1}$$\n",
    "\n",
    "and so $A_n \\subseteq A_{n + 1}$, which implies $\\cup_{m=1}^n A_m = A_n$ (since the last set, $A_n$, contains all of the previous ones).\n",
    "\n",
    "Then, from the corollary of the axiom of probability (1.8),\n",
    "\n",
    "$$ \\text{Pr}\\left\\{ \\cup_{n=1}^\\infty A_n \\right\\} = \\lim_{m \\rightarrow \\infty} \\text{Pr} \\left\\{ \\cup_{n=1}^m A_n \\right\\}$$\n",
    "\n",
    "we get the desired result,\n",
    "\n",
    "$$ \\text{Pr}\\left\\{ \\cup_{n \\geq 1} A_n \\right\\} = \\lim_{n \\rightarrow \\infty} \\text{Pr}\\left\\{ A_n \\right\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** We have:\n",
    "\n",
    "$$ \\omega \\in \\cup_{n \\geq 1} A_n \\Rightarrow \\exists n \\geq 1, X(\\omega) > x + 1/n \\Rightarrow X(\\omega) > x \\Rightarrow \\omega \\in \\left\\{ \\omega : X(\\omega) > x \\right\\}$$\n",
    "\n",
    "The implication $\\exists n \\geq 1, X(\\omega) > x + 1/n \\Rightarrow X(\\omega) > x$ can be proven by contradiction:  if $X(\\omega) \\leq x$, then $X(\\omega) \\leq x < x + 1/n$ for all $n$, and so there are no integers $n$ for which $X(\\omega) > x + 1/n$.\n",
    "\n",
    "Given the logic implication above, $\\cup_{n \\geq 1} A_n = \\left\\{ \\omega : X(\\omega) > x \\right\\}$, and so the probability of these two events is the same.  The result now follows from (a):\n",
    "\n",
    "$$ \\text{Pr}\\left\\{ X > x \\right\\} = \\text{Pr} \\left\\{ \\cup_{n \\geq 1} A_n \\right\\} = \\lim_{n \\rightarrow \\infty} \\text{Pr}\\left\\{A_n\\right\\} =  \\lim_{n \\rightarrow \\infty}\\text{Pr}\\left\\{ X > x + 1 / n \\right\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**  Since the probability of complementary events add up to 1, we can restate the result from (b) as\n",
    "\n",
    "$$ \\text{Pr}\\left\\{ X \\leq x \\right\\} = \\lim_{n \\rightarrow \\infty}\\text{Pr}\\left\\{ X \\leq x + 1 / n \\right\\} $$\n",
    "\n",
    "But this limit is the same as $\\lim_{\\epsilon \\rightarrow 0^+}\\text{Pr}\\left\\{ X \\leq x + \\epsilon \\right\\}$, by replacing each $\\epsilon$ with a potentially smaller value $r(\\epsilon) = 1/n$, where $n = \\lceil 1 / \\epsilon \\rceil$ -- since by construction $\\epsilon \\geq r(\\epsilon)$ and we are just replacing the expression under the limit with an expression that occurs for a later in the limit series:\n",
    "\n",
    "$$\\lim_{\\epsilon \\rightarrow 0^+}\\text{Pr}\\left\\{ X \\leq x + \\epsilon \\right\\} = \n",
    "\\lim_{r(\\epsilon) \\rightarrow 0^+}\\text{Pr}\\left\\{ X \\leq x + r(\\epsilon) \\right\\} = \n",
    "\\lim_{n \\rightarrow \\infty}\\text{Pr}\\left\\{ X \\leq x + 1 / n \\right\\} $$\n",
    "\n",
    "This proves the desired result -- continuity from the right for the CDF $F_X(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**  By definition, $\\tilde{F}_X(x) = \\text{Pr}\\left\\{ X < x \\right\\} = 1 - \\text{Pr}\\left\\{ -X \\leq -x \\right\\} = 1 - F_{-X}(-x) $, where $F_{-X}$ is the CDF for the random variable $-X$.  Since the CDF of random variables are continuous from the right as shown in (c), the newly defined function $\\tilde{F}_X(x)$ must be continuous from the left -- since it is a constant minus a right-continuous function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.6**.  Show that for a continuous non-negative random variable $X$,\n",
    "\n",
    "$$ \\int_0^\\infty \\text{Pr}\\left\\{ X > x \\right\\} dx = \\int_0^\\infty x f_X(x) \\; dx $$\n",
    "\n",
    "Hint 1:  First rewrite $\\text{Pr}\\left\\{ X > x \\right\\}$ on the left-hand side of (1.98) as $\\int_x^\\infty f_X(y) dy$.  Then think through, to your level of comfort, how and why the order of integration can be interchanged in the resulting expression.\n",
    "\n",
    "Hint 2:  As an alternative approach, derive (1.98) using integration by parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.\n",
    "\n",
    "$$\n",
    "\\int_0^\\infty \\text{Pr}\\left\\{ X > x \\right\\} dx = \\int_0^\\infty \\int_x^\\infty f_X(y) dy dx\n",
    "= \\int_0^\\infty \\int_0^y f_X(y) dx dy\n",
    "= \\int_0^\\infty y f_X(y) dy\n",
    "$$\n",
    "\n",
    "The order of integration above can be changed since both double integrals sweep the area \n",
    "\n",
    "$$\\{ (x, y) : x \\in [0, \\infty), y \\geq x \\} = \\{ (x, y) : y \\in [0, \\infty), 0 \\leq x \\leq y \\} $$\n",
    "\n",
    "assigning the same integrand to each point, $\\mu(x, y) = f_X(y)$.\n",
    "\n",
    "The result follows by renaming the variable $y$ as $x$ in the last expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.7**.  Suppose $X$ and $Y$ are discrete random variables with the PMF $p_{XY}(x_i, y_j)$.  Show (a picture will help) that this is related to the joint CDF by\n",
    "\n",
    "$$ p_{XY}(x_i, y_j) = \\lim_{\\delta > 0, \\delta \\rightarrow 0} \\left[ F(x_i, y_j) - F(x_i - \\delta, y_j) - F(x_i, y_j - \\delta) + F(x_i - \\delta, y_j - \\delta) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.\n",
    "\n",
    "Since $X, Y$ are discrete random variables, their joint CDF can be expressed as a sum of countably many elements with non-zero probability mass,\n",
    "\n",
    "$$ F(x, y) = \\sum_{a: x_a \\leq x} \\sum_{b : y_b \\leq y} p_{XY}(x_a, y_b) $$\n",
    "\n",
    "Therefore, the expression inside the limit reduces to\n",
    "\n",
    "$$ F(x_i, y_j) - F(x_i - \\delta, y_j) - F(x_i, y_j - \\delta) + F(x_i - \\delta, y_j - \\delta) = \\sum_{a: x_i - \\delta < x_a \\leq x_i} \\sum_{b: y_j - \\delta < y_b \\leq y_j} p_{XY}(x_a, y_b) $$\n",
    "\n",
    "For any $x_a < x_i$ and for any $y_b < y_j$, we can select a $\\delta$ that puts them outside of the interval $(x_i - \\delta, x_i] \\times (y_j - \\delta, y_j]$ -- for example, pick $\\delta = \\min \\{ (x_i - x_a) / 2, (y_j - y_b) / 2 \\}$.  Therefore, all terms other than $p_XY(x_i, y_j)$ will be dropped from the sum on the limit, and the result holds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.8**.  A variation of Example 1.5.1 is to let $M$ be a random variable that takes on both positive and negative values with the PMF\n",
    "\n",
    "$$ p_M(m) = \\frac{1}{2 |m| (|m| + 1) }$$\n",
    "\n",
    "In other words, $M$ is symmetric around 0 and $|M|$ has the same PMF as the non-negative random variable of Example 1.5.1.\n",
    "\n",
    "**(a)** Show that $\\sum_{m \\geq 0} m p_M(m) = \\infty$ and $\\sum_{m < 0} m p_M(m) = -\\infty$.  (Thus show that the expectation of $M$ not only does not exist but is undefined even as an extended real number.)\n",
    "\n",
    "**(b)** Suppose that the terms in $\\sum_{m=-\\infty}^\\infty m p_M(m)$ are summed in the order of two positive terms for each negative term (i.e. in the order 1, 2, -1, 3, 4, -2, 5, $\\cdots$). Find the limiting value of the partial sums in this series.  Hint: You may find it helpful to know that\n",
    "\n",
    "$$ \\lim_{n \\rightarrow \\infty} \\left[ \\sum_{i=1}^n \\frac{1}{i} - \\int_1^n \\frac{1}{x} dx \\right] = \\gamma $$\n",
    "\n",
    "where $\\gamma$ is the Euler-Mascheroni constant, $\\gamma = 0.57721\\cdots$\n",
    "\n",
    "**(c)** Repeat (b) where, for any given integer $k > 0$, the order of summation is $k$ positive terms for each negative term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** We have:\n",
    "\n",
    "$$ \\sum_{m=1}^n m p_M(m) = \\frac{1}{2(m + 1)} = \\frac{1}{2} \\sum_{m=2}^n \\frac{1}{m} = \\frac{1}{2} \\left( H_n - 1 \\right) $$\n",
    "\n",
    "where $H_n = \\sum_{m=1}^n \\frac{1}{m}$ is the $n$-th term on the harmonic series.\n",
    "\n",
    "Since the harmonic series diverges, $\\sum_{m \\geq 0} m p_M(m) = \\infty$.\n",
    "\n",
    "Similarly,\n",
    "\n",
    "$$ \\sum_{m=-n}^{-1} m p_M(m) = -\\sum_{m=1}^n m p_M(m) = -\\frac{1}{2} \\left( H_n - 1 \\right) $$\n",
    "\n",
    "so $\\sum_{m < 0} m p_M(m) = -\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  The sum after $3n$ terms in the provided order is the sum of the first $2n$ positive terms and the first $n$ negative terms:\n",
    "\n",
    "$$ \\sum_{m=1}^{2n} m p_M(m) + \\sum_{m=-n}^{-1} m p_M(m) = \\frac{1}{2} \\left(H_{2n} - H_n\\right) $$\n",
    "\n",
    "The difference between $H_n$ and $\\ln n$ converges to the Euler-Mascheroni constant $\\gamma$,\n",
    "\n",
    "$$ H_n = \\ln n + \\gamma + \\epsilon_n$$\n",
    "\n",
    "where $\\epsilon_n \\sim 1/2n$ goes to 0 as $n$ goes to infinity.\n",
    "\n",
    "Then,\n",
    "\n",
    "$$ \\frac{1}{2} \\left(H_{2n} - H_n\\right) = \\frac{1}{2} \\left( \\ln 2 + \\epsilon_{2n} - \\epsilon_n \\right) $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\lim_{n \\rightarrow \\infty} \\frac{1}{2} \\left(H_{2n} - H_n\\right) = \\frac{\\ln 2}{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**\n",
    "\n",
    "By an analogous argument, adding up the first $kn$ positive terms and the first $n$ negative terms gives us:\n",
    "\n",
    "$$ \\sum_{m=1}^{kn} m p_M(m) + \\sum_{m=-n}^{-1} m p_M(m) = \\frac{1}{2} \\left(H_{kn} - H_n\\right) $$\n",
    "\n",
    "And we have\n",
    "\n",
    "$$ \\frac{1}{2} \\left(H_{kn} - H_n\\right) = \\frac{1}{2} \\left( \\ln k + \\epsilon_{kn} - \\epsilon_n \\right) $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\lim_{n \\rightarrow \\infty} \\frac{1}{2} \\left(H_{kn} - H_n\\right) = \\frac{\\ln k}{2} $$\n",
    "\n",
    "The exercise's point is then to show that we can sum up the terms in an an order to approach an arbitrarily large value (by e.g. picking $k$ such that $\\ln k / 2$ is sufficiently large)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.9 (Proof of Theorem 1.4.1)**.  The bounds on the binomial in this theorem are based on the *Stirling bounds*.  These say that for all $n \\geq 1$, $n!$ is upper and lower bound by\n",
    "\n",
    "$$ \\sqrt{2 \\pi n} \\left( \\frac{n}{e} \\right)^n < n! < \\sqrt{2 \\pi n} \\left( \\frac{n}{e} \\right)^n e^{1 / 12 n}$$\n",
    "\n",
    "The ratio $\\sqrt{2 \\pi n} \\left( n/e \\right)^n / n!$ of the first two terms is monotonically increasing with $n$ toward the limit 1, and the ratio $\\sqrt{2 \\pi n} \\left( n/e \\right)^n \\exp (1 / 12n) / n!$ is monotonically decreasing toward 1.  The upper bound is more accurate, but the lower bound is simpler and known as the Stirling approximation.  See [8] for proofs and further discussion of the above facts.\n",
    "\n",
    "**(a)** Show from (1.99) and from the above monotone property that \n",
    "\n",
    "$$ \\binom{n}{k} < \\sqrt{\\frac{n}{2 \\pi k (n - k)}} \\frac{n^n}{k^k (n - k)^{n - k}} $$\n",
    "\n",
    "Hint: First show that $n! / k! < \\sqrt{n / k} \\; n^n k^{-k} e^{-n+k}$ for $k < n$.\n",
    "\n",
    "**(b)** Use the result of (a) to upper bound $p_{S_n}(k)$ by\n",
    "\n",
    "$$ p_{S_n}(k) < \\sqrt{\\frac{n}{2 \\pi k (n - k)}} \\frac{p^k (1 - p)^{n - k} n^n}{k^k (n - k)^{n - k}} $$\n",
    "\n",
    "Show that this is equivalent to the upper bound in Theorem 1.41.\n",
    "\n",
    "**(c)** Show that\n",
    "\n",
    "$$ \\binom{n}{k} > \\sqrt{\\frac{n}{2 \\pi k (n - k)}} \\frac{n^n}{k^k (n - k)^{n - k}} \\left[ 1 - \\frac{n}{12k (n - k)} \\right] $$\n",
    "\n",
    "**(d)** Derive the lower bound in Theorem 1.41.\n",
    "\n",
    "**(e)** Show that $D(\\tilde{p} \\Vert p) = \\tilde{p} \\ln(\\tilde{p} / p) + (1 - \\tilde{p}) \\ln [ (1 - \\tilde{p}) / (1 - p) ]$ is 0 at $\\tilde{p} = p$ and non-negative elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  Since the ratio between the first two terms on the Stirling bound is monotonically increasing, for $k < n$ we have:\n",
    "\n",
    "$$ \\sqrt{2 \\pi k} \\left( \\frac{k}{e} \\right)^k \\frac{1}{k!} < \\sqrt{2 \\pi n} \\left( \\frac{n}{e} \\right)^n \\frac{1}{n!} $$\n",
    "\n",
    "which can be rewritten as\n",
    "\n",
    "$$ \\frac{n!}{k!} < \\sqrt{\\frac{n}{k}} n^n k^{-k}e^{-n+k}$$\n",
    "\n",
    "By using the inverse of Stirling lower bound for $n - k$, we get\n",
    "\n",
    "$$ \\frac{1}{(n - k)!} < \\sqrt{\\frac{1}{2 \\pi (n - k)}}\\frac{e^{n - k}}{(n - k)^{n-k}}$$\n",
    "\n",
    "Multiplying the last two inequalities, we get\n",
    "\n",
    "$$ \\binom{n}{k} = \\frac{n!}{k! (n - k)!} < \\sqrt{\\frac{n}{2 \\pi k (n - k)}} \\frac{n^n}{k^k (n - k)^{n-k}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  The upper bound in Theorem 1.41 is\n",
    "\n",
    "$$ p_{S_n}(\\tilde{p}n) < \\sqrt{\\frac{1}{2 \\pi n \\tilde{p} (1 - \\tilde{p})}} \\exp [- n D(\\tilde{p} \\Vert p)]$$\n",
    "\n",
    "where $\\tilde{p} = k / n$. \n",
    "\n",
    "The PMF for the binomial distribution is\n",
    "\n",
    "$$ p_{S_n}(k) = \\binom{n}{k} p^k (1 - p)^{n - k} $$\n",
    "\n",
    "so the inequality follows by multiplying both sides of the result in (a) by $p^k (1 - p)^{n - k}$:\n",
    "\n",
    "$$ p_{S_n}(k) = \\binom{n}{k}p^k (1 - p)^{n - k}  < \\sqrt{\\frac{n}{2 \\pi k (n - k)}} \\frac{p^k (1 - p)^{n - k} n^n}{k^k (n - k)^{n-k}}$$\n",
    "\n",
    "But\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\exp [- n D(\\tilde{p} \\Vert p)] &= \\exp \\left\\{ -n\\tilde{p} \\ln \\left( \\frac{\\tilde{p}}{p} \\right) - n(1 - \\tilde{p}) \\ln \\left( \\frac{1 - \\tilde{p}}{1 - p} \\right) \\right\\}  \\\\\n",
    "&= \\exp \\left\\{ -k \\ln \\left( \\frac{k}{np} \\right) - (n - k) \\ln \\left( \\frac{n - k}{n(1 - p)} \\right) \\right\\} \\\\\n",
    "&= \\left(\\exp \\left\\{ \\ln \\left( \\frac{k}{np} \\right) \\right\\}\\right)^{-k}  \\left( \\exp \\left\\{ \\ln \\left( \\frac{n - k}{n(1 - p)} \\right) \\right\\}  \\right)^{-n-k} \\\\\n",
    "&= \\frac{n^k p^k}{k^k} \\frac{n^{n - k} (1 - p)^{n - k}}{(n - k)^{n - k}} \\\\\n",
    "&= \\frac{p^k (1 - p)^{n - k} n^n}{k^k (n - k)^{n - k}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and so\n",
    "\n",
    "$$ \\sqrt{\\frac{1}{2 \\pi n \\tilde{p} (1 - \\tilde{p})}} \\exp [- n D(\\tilde{p} \\Vert p)] = \\sqrt{\\frac{n}{2 \\pi k (n - k)}} \\frac{p^k (1 - p)^{n - k} n^n}{k^k (n - k)^{n - k}} $$\n",
    "\n",
    "therefore the inequality we obtained is equivalent to the upper bound of Theorem 1.41."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**.  Let's do a proof similar to the one in (a), but using the fact that the ratio between the upper bound in the Stirling bound is monotonically decreasing; for $k < n$,\n",
    "\n",
    "$$\\sqrt{2 \\pi n} \\left( \\frac{n}{e} \\right)^n e^{1 / 12n} \\frac{1}{n!} < \\sqrt{2 \\pi k} \\left( \\frac{k}{e} \\right)^k e^{1 / 12k} \\frac{1}{k!}$$\n",
    "\n",
    "Rearranging the terms, we get a lower bound for $n! / k!$,\n",
    "\n",
    "$$ \\frac{n!}{k!} > \\sqrt{\\frac{n}{k}} n^n k^{-k} \\exp \\left\\{ -n + \\frac{1}{12n} + k - \\frac{1}{12k}\\right\\} $$\n",
    "\n",
    "By using the inverse of the Stirling upper bound for $n - k$, we get\n",
    "\n",
    "$$ \\frac{1}{(n - k)!} > \\sqrt{\\frac{1}{2 \\pi (n - k)}}\\frac{1}{(n - k)^{n-k}} \\exp \\left\\{ (n - k) - \\frac{1}{12(n - k)}\\right\\}$$\n",
    "\n",
    "Multiplying these inequalities, we get\n",
    "\n",
    "$$ \\binom{n}{k} = \\frac{n!}{k! (n - k)!} > \\sqrt{\\frac{n}{2 \\pi k (n - k)}} \\frac{n^n}{k^k (n - k)^{n - k}} \\exp \\left\\{ \\frac{1}{12n} - \\frac{1}{12k} - \\frac{1}{12(n - k)}\\right\\} $$\n",
    "\n",
    "In order the obtain the result, now it suffices to show that this is a stronger inequality, that is,\n",
    "\n",
    "$$ \\exp \\left\\{ \\frac{1}{12n} - \\frac{1}{12k} - \\frac{1}{12(n - k)} \\right\\} \\geq 1 - \\frac{n}{12k (n - k)}$$\n",
    "\n",
    "We have $\\exp x < 1 - x$ for $x < 0$, since $f(x) = e^x + x$ has value $f(0) = 1$ and $f$ is monotonically increasing.  Then, since $k < n$, we have\n",
    "\n",
    "$$ \\frac{1}{12n} - \\frac{1}{12k} - \\frac{1}{12(n - k)} < 0 $$\n",
    "\n",
    "and so\n",
    "\n",
    "$$ \\exp \\left\\{ \\frac{1}{12n} - \\frac{1}{12k} - \\frac{1}{12(n - k)} \\right\\} < \\frac{1}{12n} - \\frac{1}{12k} - \\frac{1}{12(n - k)} $$\n",
    "\n",
    "It then will suffice to prove the even stronger result that\n",
    "\n",
    "$$\n",
    "\\frac{1}{12n} - \\frac{1}{12k} - \\frac{1}{12(n - k)} < 1 - \\frac{n}{12k (n - k)}\n",
    "$$\n",
    "\n",
    "which is true, since it is equivalent to $\\frac{1 - 12n}{12n} < 0$ and we have $n > 1/12$.\n",
    "\n",
    "Therefore, the desired (weaker) upper bound holds,\n",
    "\n",
    "$$ \\binom{n}{k} > \\sqrt{\\frac{n}{2 \\pi k (n - k)}} \\frac{n^n}{k^k (n - k)^{n - k}} \\left[ 1 - \\frac{n}{12k (n - k)} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**  The upper bound in Theorem 1.41 is\n",
    "\n",
    "$$ p_{S_n}(\\tilde{p}n) > \\left(1 - \\frac{1}{12n\\tilde{p}(1 - \\tilde{p})} \\right) \\sqrt{\\frac{1}{2 \\pi n \\tilde{p} (1 - \\tilde{p})}} \\exp [- n D(\\tilde{p} \\Vert p)]$$\n",
    "\n",
    "By multiplying the bound of (c) by $p^k (1-p)^{n-k}$, we get:\n",
    "\n",
    "$$ p_{S_n}(k) = \\binom{n}{k} p^k (1 - p)^{n-k} > \\sqrt{\\frac{n}{2 \\pi k (n - k)}} \\frac{p^k (1 - p)^{n-k} n^n}{k^k (n - k)^{n - k}} \\left[ 1 - \\frac{n}{12k (n - k)} \\right] $$\n",
    "\n",
    "But, if $\\tilde{p} = k / n$, then\n",
    "\n",
    "$$ \\sqrt{\\frac{n}{2 \\pi k (n - k)}} \\left[ 1 - \\frac{n}{12k (n - k)} \\right] = \\left(1 - \\frac{1}{12n\\tilde{p}(1 - \\tilde{p})} \\right) \\sqrt{\\frac{1}{2 \\pi n \\tilde{p} (1 - \\tilde{p})}} $$\n",
    "\n",
    "and, as we proved in (b) that \n",
    "\n",
    "$$ \\exp [- n D(\\tilde{p} \\Vert p)] = \\frac{p^k (1 - p)^{n - k} n^n}{k^k (n - k)^{n - k}} $$\n",
    "\n",
    "the desired result follows by multiplying the last two equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)**  This result is a particular case of Gibbs' inequality, which states that the Kullback-Leibler divergence, or relative entropy, is non-negative:\n",
    "\n",
    "$$ D_{KL}(P \\Vert Q) = \\sum_i p_i \\ln \\frac{p_i}{q_i} \\geq 0 $$\n",
    "\n",
    "where $P, Q$ are probability distributions, with $\\sum_i p_i = \\sum_i q_i = 1$.\n",
    "\n",
    "In this problem, we have the (negative) binary KL divergence, with $(p_1, p_2) = (\\tilde{p}, (1 - \\tilde{p})$ and $(q_1, q_2) = (p, 1 - p)$.\n",
    "\n",
    "To demonstrate Gibbs' inequality, note that $\\ln$ is strictly concave, so using Jensen's inequality we have\n",
    "\n",
    "$$ -D_{KL}(P \\Vert Q) = \\sum_i p_i \\ln \\frac{q_i}{p_i} \\leq \\ln \\sum_i p_i \\frac{q_i}{p_i} = \\ln \\sum_i q_i = 0$$\n",
    "\n",
    "with equality holding only when\n",
    "\n",
    "$$ \\frac{q_1}{p_1} = \\frac{q_2}{p_2} = \\cdots $$\n",
    "\n",
    "which in our case implies\n",
    "\n",
    "$$ \\frac{p}{\\tilde{p}} = \\frac{1 - p}{1 - \\tilde{p}} $$\n",
    "\n",
    "or $\\tilde{p} = p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.10**.  Let $X$ be a ternary random variable taking on the three values 0, 1, 2 with probabilities $p_0, p_1, p_2$, respectively.  Find the median of $X$ for each of the three cases below.\n",
    "\n",
    "**(a)** $p_0 = 0.2, p_1 = 0.4, p_2 = 0.4$.\n",
    "\n",
    "**(b)** $p_0 = 0.2, p_1 = 0.2, p_2 = 0.6$.\n",
    "\n",
    "**(c)** $p_0 = 0.2, p_1 = 0.3, p_2 = 0.5$.\n",
    "\n",
    "Note 1: The median is not unique in (c).  Find the interval of the values that are medians. \n",
    "\n",
    "Note 2:  Some people force the median to be distinct by defining it as the midpoint of the interval satisfying the definition given here.\n",
    "\n",
    "**(d)**  Now suppose that $X$ is non-negative and continuous with the density $f_X(x) = 1$ for $0 \\leq x \\leq 0.5$ and $f_X(x) = 0$ for $0.5 \\leq x \\leq 1$.  We know that $f_X(x)$ is positive for all $x > 1$, but it is otherwise unknown.  Find the median or interval of medians.\n",
    "\n",
    "The median is sometimes (incorrectly) defined as that $\\alpha$ for which $\\text{Pr} \\left\\{ X > \\alpha \\right\\} = \\text{Pr} \\left\\{ X < \\alpha \\right\\}$.  Show that it is possible for no such $\\alpha$ to exist.  Hint: look at the examples above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** The unique median is $\\alpha = 1$, since $\\text{Pr}\\{X \\leq 1\\} = 0.6 \\geq 1/2$ and $\\text{Pr}{X \\geq 1} = 0.8 \\geq 1/2$.  These criteria do not apply for $\\alpha \\neq 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** The unique median is $\\alpha = 2$, since $\\text{Pr}\\{X \\leq 2\\} = 1.0 \\geq 1/2$ and $\\text{Pr}\\{X \\geq 1\\} = 0.6 \\geq 1/2$.  These criteria do not apply for $\\alpha \\neq 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** For $\\alpha \\in [1, 2]$ the median condition applies: $\\text{Pr}\\{X \\leq \\alpha\\} \\geq 0.5$ and $\\text{Pr}\\{X \\geq \\alpha\\} \\geq 0.5$.  The median condition does not otherwise apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**  By construction, $\\text{Pr}\\{X \\geq \\alpha\\} \\geq 0.5$ for $\\alpha \\geq 0.5$, so all medians must satisfy this condition.  Additionally, $\\text{Pr}\\{X \\geq \\alpha\\} > 0.5$ if $x > 1$, so $\\alpha$ must satisfy the reverse of this condition.  Therefore, the interval of medians is $[0.5, 1]$.\n",
    "\n",
    "The distribution in (a) is an example of a distribution where the incorrect definition of median yields no values:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|c|c}\n",
    "\\alpha & \\text{Pr}\\{ X > \\alpha \\} & \\text{Pr}\\{ X < \\alpha \\} \\\\\n",
    "\\hline\n",
    "\\alpha < 0 & 1 & 0 \\\\\n",
    "\\alpha = 0 & 0.8 & 0 \\\\\n",
    "0 < \\alpha < 1 & 0.8 & 0.2 \\\\\n",
    "\\alpha = 1 & 0.4 & 0.2 \\\\\n",
    "1 < \\alpha < 2 & 0.4 & 0.6 \\\\\n",
    "\\alpha = 2 & 0 & 0.6 \\\\\n",
    "\\alpha > 2 & 0 & 1\n",
    "\\end{array}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
